{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBKBLx6bf3Ok"
   },
   "source": [
    "# Download the binary version of CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\student\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install wget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: wget.py [options] URL\n",
      "\n",
      "options:\n",
      "  -o --output FILE|DIR   output filename or directory\n",
      "  -h --help\n",
      "  --version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79P95-BriJBX",
    "outputId": "e3f489af-b14e-4385-fb45-5121a474b605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [......................................................................] 170498071 / 170498071"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "# ! wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "import wget\n",
    "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "myfile = wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKE4uMeYiLhq",
    "outputId": "2bed3d1c-8e89-4bbd-c4cd-725fda5c04b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tar: Error opening archive: Failed to open '/content/cifar-10-python.tar.gz'\n"
     ]
    }
   ],
   "source": [
    "# extract the data batches\n",
    "!tar -xvf  /content/cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gW6iV8UdiOdU"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mk\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle as pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC2ekH_CgMq_"
   },
   "source": [
    "# Extract the data from the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CImIYWhiSJV"
   },
   "outputs": [],
   "source": [
    "# load a single batch of CIFAR10\n",
    "def load_CIFAR_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # load the content of the pickle file\n",
    "        datadict = pickle.load(f, encoding='latin1')\n",
    "        # get the data\n",
    "        X = datadict['data']\n",
    "        # get the labels\n",
    "        Y = datadict['labels']\n",
    "        # conver them into numpy arrays\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        # return the data and labels arrays\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0VUq4SiiUcV"
   },
   "outputs": [],
   "source": [
    "# load all the batches\n",
    "def load_CIFAR10(path):\n",
    "    # to store the data of all the batches\n",
    "    xs = []\n",
    "    # to store the labels of all the batches\n",
    "    ys = []\n",
    "    # iterate over the batches from 1 to 5\n",
    "    for number in range(1,6):\n",
    "        # get the path of the file\n",
    "        file = os.path.join(path, 'data_batch_%d' % (number))\n",
    "        # get the content of the batch\n",
    "        X, Y = load_CIFAR_batch(file)\n",
    "        # append the data and labels of each batch\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    # concatenate all the data of all batches\n",
    "    Xtrain = np.concatenate(xs)\n",
    "    # concatenate all the labels of all batches\n",
    "    Ytrain = np.concatenate(ys)\n",
    "    # load the test data and labels from the test batch\n",
    "    Xtest, Ytest = load_CIFAR_batch(os.path.join(path, 'test_batch'))\n",
    "    # return\n",
    "    return Xtrain, Ytrain, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUGMKO-ligsp"
   },
   "outputs": [],
   "source": [
    "def get_CIFAR10_data():\n",
    "    # get the train and test data and labels from the raw dataset\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10('/content/cifar-10-batches-py')\n",
    "    # convert the train data into float32\n",
    "    x_train = X_train.astype('float32')\n",
    "    # convert the test data into float32\n",
    "    x_test = X_test.astype('float32')\n",
    "    # normalize the train and test data\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    # return\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpnFFeZPivJx"
   },
   "outputs": [],
   "source": [
    "# extract the data\n",
    "x_train, y_train, x_test, y_test = get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bk8aDvYri1L7",
    "outputId": "ac8df445-66af-429b-a7d1-ecdefd63f871"
   },
   "outputs": [],
   "source": [
    "print('Train data shape  : ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Test data shape   : ', x_test.shape)\n",
    "print('Test labels shape : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJxPtLItglC4",
    "outputId": "020fe655-e315-4ce2-d795-81bd8577223d"
   },
   "outputs": [],
   "source": [
    "print('The training data contains %d images and %d labels' %(x_train.shape[0], y_train.shape[0]))\n",
    "print('The testing  data contains %d images and %d labels' %(x_test.shape[0], y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_neA7tinD2O"
   },
   "outputs": [],
   "source": [
    "# define a function to rotate the images\n",
    "def rotate(imgs):\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs[i] = np.rot90(imgs[i], k=-1)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5mdcxSZtmVK"
   },
   "outputs": [],
   "source": [
    "# define a function to reshape the each row of the training data set into an image\n",
    "# of size 32, 32, 3\n",
    "# since this is the binary version of the data, we also need to swap the axes\n",
    "# and finally all the iamges need to be rotated\n",
    "def convert_into_images(data):\n",
    "    data_shaped = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    data_swaped = np.swapaxes(data_shaped, 1, 3)\n",
    "    data_rot = rotate(data_swaped)\n",
    "    return data_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMMW9aYwt2TT"
   },
   "outputs": [],
   "source": [
    "# restore the training and testing images\n",
    "x_train = convert_into_images(x_train)\n",
    "x_test = convert_into_images(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VtMouZwMouo7",
    "outputId": "331cdb7c-6287-4b5a-a233-478953d03f0c"
   },
   "outputs": [],
   "source": [
    "# to make sure that the training and testing data have the proper shape\n",
    "print('the training data has %d images of the shape : (%d, %d, %d)' % (x_train.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3]))\n",
    "print('the testing  data has %d images of the shape : (%d, %d, %d)' % (x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdCQWfeBpoR2"
   },
   "source": [
    "# Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jV_vxzthilzn"
   },
   "outputs": [],
   "source": [
    "# define the labels\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0n0JsfqyncHy"
   },
   "outputs": [],
   "source": [
    "# define a function to plot sample images\n",
    "def plot_sample_images(xdata, ydata):\n",
    "    # define 25 subplots(5, 5)\n",
    "    f, ax = plt.subplots(5, 5)\n",
    "    for row in range(5):\n",
    "        for col in range(5):\n",
    "            # get a random index\n",
    "            idx = np.random.randint(0, xdata.shape[0])\n",
    "            # show the image\n",
    "            ax[row,col].imshow(xdata[idx])\n",
    "            # show the label of each image\n",
    "            ax[row,col].set_title(labels[ydata[idx]], fontsize = 8)\n",
    "            # hide the axes\n",
    "            ax[row,col].get_xaxis().set_visible(False)\n",
    "            ax[row,col].get_yaxis().set_visible(False)\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "5BejXq5MlvfX",
    "outputId": "7ea73be3-b715-4673-c94b-aa466b764f48"
   },
   "outputs": [],
   "source": [
    "# plot 25 random images from the training images with thier labels\n",
    "plot_sample_images(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "HehaJIQznuVc",
    "outputId": "e6985c2b-3544-414b-c600-2f758565352c"
   },
   "outputs": [],
   "source": [
    "# plot 25 random images from the testing images with thier labels\n",
    "plot_sample_images(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "0gYh6-wDoARC",
    "outputId": "7f2a3ada-1ff3-4b55-f7f0-a659b50c31ad"
   },
   "outputs": [],
   "source": [
    "# plot the distribution of each class in the training data\n",
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "plt.barh(labels, counts)\n",
    "plt.title('class distribution in training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "GpjuVgUXpyYr",
    "outputId": "a14435c0-d87b-44ec-f236-3f392ac3452e"
   },
   "outputs": [],
   "source": [
    "# plot the distribution of each class in the testing data\n",
    "classes, counts = np.unique(y_test, return_counts=True)\n",
    "plt.barh(labels, counts)\n",
    "plt.title('Class distribution in testing data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AS2W1H2qvqHF"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mR9K5FfJp9iK"
   },
   "outputs": [],
   "source": [
    "# transform target variable into one-hotencoding\n",
    "categorical_y_train = to_categorical(y_train, 10)\n",
    "categorical_y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iXDPUzKqjMk"
   },
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owgK813Hqtzj"
   },
   "outputs": [],
   "source": [
    "# define a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# block 1\n",
    "# conv layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "# batch norm layer\n",
    "model.add(BatchNormalization())\n",
    "# conv layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "# batch norm layer\n",
    "model.add(BatchNormalization())\n",
    "# pooling layer\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# block 2\n",
    "# conv layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "# batch norm layer\n",
    "model.add(BatchNormalization())\n",
    "# conv layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "# batch norm layer\n",
    "model.add(BatchNormalization())\n",
    "# pooling layer\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# block 3\n",
    "# conv layer\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "# batch norm layer\n",
    "model.add(BatchNormalization())\n",
    "# conv layer\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "# batch norm layer\n",
    "model.add(BatchNormalization())\n",
    "# pooling layer\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten the input for the mlp\n",
    "model.add(Flatten())\n",
    "# first FC layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "# second FC layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfNORjDTr0dX"
   },
   "outputs": [],
   "source": [
    "# define the metrics\n",
    "METRICS = ['accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a626HYDmrssS"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# with categorical crossentropy loss, Adam optimizer and the defined metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "On9zVfqgsGSm",
    "outputId": "40990348-ea01-4d5b-e2c7-3811a3159229"
   },
   "outputs": [],
   "source": [
    "# print the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eh5vAzlxL9wu"
   },
   "outputs": [],
   "source": [
    "# data Augmentation\n",
    "data_generator = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "train_generator = data_generator.flow(x_train, categorical_y_train, 32)\n",
    "steps_per_epoch = x_train.shape[0] // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSWKQlHpsS5K",
    "outputId": "c31228b2-6247-40f1-94be-20a84ca28b3d"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "his = model.fit(train_generator,\n",
    "              epochs=50,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_data=(x_test, categorical_y_test),\n",
    "              batch_size=32,\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDH7MoznsbP-"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "J8B1CIUTPK-D",
    "outputId": "259f4adc-694e-448c-c59f-0d951c0a503c"
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "plt.figure(figsize=(8, 12))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(his.history['loss'], label='Loss')\n",
    "plt.plot(his.history['val_loss'], label='val_Loss')\n",
    "plt.title('Loss Function Evolution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(his.history['accuracy'], label='accuracy')\n",
    "plt.plot(his.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('Accuracy Function Evolution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(his.history['precision'], label='precision')\n",
    "plt.plot(his.history['val_precision'], label='val_precision')\n",
    "plt.title('Precision Function Evolution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(his.history['recall'], label='recall')\n",
    "plt.plot(his.history['val_recall'], label='val_recall')\n",
    "plt.title('Recall Function Evolution')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Jk-8d10PVma",
    "outputId": "e27122f4-e209-46fc-c4c1-8aae062f38b6"
   },
   "outputs": [],
   "source": [
    "# calculate and print test accuracy\n",
    "evaluation = model.evaluate(x_test, categorical_y_test)\n",
    "print(f'Test Accuracy : {evaluation[1] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "id": "hh8Z4L_jPnvH",
    "outputId": "91b84179-9180-4fbc-c4d7-9d6e30b5153d"
   },
   "outputs": [],
   "source": [
    "# get predictions\n",
    "y_pred = model.predict(x_test)\n",
    "# get the predicted class\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "# find the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp = disp.plot(xticks_rotation='vertical', ax=ax,cmap='summer')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAJJaypIPwzX",
    "outputId": "b6d3d874-489e-43ab-ed0a-9e877e19662a"
   },
   "outputs": [],
   "source": [
    "print('                      classification_report                      ')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgHIhILUtFPh"
   },
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "XVpQGYHSP0bq",
    "outputId": "8b52d185-9de6-4914-b220-59be59f6df67"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2))\n",
    "plt.axis('off')\n",
    "# get an image from the test images\n",
    "test_image = x_test[1000]\n",
    "# show the image\n",
    "plt.imshow(test_image)\n",
    "# predict the class of the image\n",
    "pred_class = np.argmax(model.predict(test_image.reshape(1, 32, 32, 3)))\n",
    "# print the actual class of the image\n",
    "print(f\" the actual class of the image is : {labels[y_test[1000]]}\")\n",
    "# print the predicted class of the image\n",
    "print(f\"the predicted class by the model is : {labels[pred_class]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gA6aJiIWwcWl"
   },
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb8bOW2mQc8b",
    "outputId": "43e5b915-dc56-4cbb-d475-0f648b43c67d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('cifar10_model.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
